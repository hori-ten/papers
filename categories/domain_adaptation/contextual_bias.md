# Abstract
既存のモデルは，認識精度を向上させるために，物体間の共起とそのcontextを利用することが多い．本論文の目標は，contextがない場合にもカテゴリを正確に認識することである．

## Contributions
1. ネットワークに「正しいものから学ぶ」ことを教える目的で，共起するカテゴリのクラス活性化マップ(Class Activation Maps, CAM)間の重なりを最小化する方法を提案する．  
1. CAMベースの方法から得られた知見をもとに，カテゴリからcontextを装飾する特徴表現を学習する第二の方法を提案する．  
1. オブジェクト分類，属性分類という２つのタスクに両手法を適用し，カテゴリが典型的なcontextから外れて出現するような困難なケースにおいて，ベースラインよりも大幅な精度向上を達成した．

# 問題設定
 - 訓練データ分布中のいくつかのカテゴリは，共起バイアスに大きく影響を受ける(biased categories)．  
   - 例えば，COCO-Stuffには，"ski "が "person "と共起する画像が2209枚あるが，"person "なしで "ski "が出現する画像は29枚しかない．このような偏ったデータに基づいて学習されたモデルは，"ski "が単独で出現する場合を認識できない可能性がある． 
 - 本論文での目標は，(1)"ski "が単独で出現したときに正しく識別し，(2)"ski "が "person "と共起したときに性能を落とさないことである．

## バイアスの定義
![bias](https://ar5iv.labs.arxiv.org/html/2001.03152/assets/x2.png)  
カテゴリbとcが共起している場合と，bのみが出現している場合の比をbias(b,c)とする(前述の例では，bias(ski,person)=2209/29となる)．  
これを利用して，データセット中それぞれのカテゴリbに対し，最もバイアスの値が大きく，かつ少なくとも10~20%の確率でbと共起するカテゴリcを特定する．

# 提案手法
1. 弱い位置注釈としてクラス活性化マップ(CAM)を利用し，biased categories間の空間的重複を最小化する．
2. 1の知見を基に，biased categoriesがcontextと共起する場合はその共有を促し，contextが単独で出現する場合はそれを抑制する．

## 提案1. 弱い位置注釈としてCAMを導入
カテゴリbの殆どはカテゴリcと共起するため，モデルはcの画素領域に依存してbを予測する可能性がある．これは特に，cの存在しない画像でモデルをテストする場合に問題となる．
そこで，クラス活性化マップ(CAM)をオブジェクト定位情報の代わりに使用することで，モデルに位置注釈を使わずcの画素領域への依存を少なくするよう明示的に強制する．  

![CAM](https://ar5iv.labs.arxiv.org/html/2001.03152/assets/x3.png)  

ここで，CAM(i,r)は，与えられた画像iとクラスrに対して，モデルがrを識別するために使用する画像領域を示す．  

### 損失関数  
biased categoriesのペア(b,c)に対して以下の損失関数を用いることで，それらのCAMの重複が小さくなるようにする．  

$L_O=\displaystyle\sum_{i\in \mathbb I_b	\cap \mathbb I_c} CAM(i,b) \odot CAM(i,c) $  

上式は重なりを最小化しようとする一方で，bとcのCAMがそれらの実際のピクセル領域から離れてドリフトするような解を導く可能性もある．これを防ぐために正則化項 $L_R$ を導入する．具体的には，標準的な分類タスクのために(オフラインで)別個のネットワークを事前学習し，そこからbとcのCAMpreを生成する．そして，各カテゴリのCAMをCAMpreから予測される画素領域に近づけるようにする．  

$L_R=\displaystyle\sum_{i\in \mathbb I_b	\cap \mathbb I_c} |CAM_{pre}(i,b) - CAM(i,b)| + |CAM_{pre}(i,c) - CAM(i,c)| $  

マルチラベル分類のタスクには，標準的なバイナリクロスエントロピー損失( $L_{BCE}$ )を使う．従って，最終的な損失は次のようになる．  

$L_{CAM}=\lambda_1 L_O + \lambda_2 L_R + L_{BCE}$

## 提案2. 特徴分割と選択的なcontextの抑制

